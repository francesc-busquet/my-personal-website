<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.54">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-01-07">

<title>Introductory voice analytics with R – Francesc Busquet</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../assets/favicon/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>
  
  function getGiscusTheme() {
  const quartoTheme = localStorage.getItem("quarto-color-scheme");
  const giscusTheme = quartoTheme === "alternate" ? "dark" : "light";
  return giscusTheme;
}

function setGiscusTheme() {
  function sendMessage(message) {
    const iframe = document.querySelector('iframe.giscus-frame');
    if (!iframe) return;
    iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
  }
  sendMessage({
    setConfig: {
      theme: getGiscusTheme(),
    },
  });
}

document.addEventListener('DOMContentLoaded', function () {
  const giscusAttributes = {
    "src": "https://giscus.app/client.js",
    "data-repo": "francesc-busquet/my-personal-website",
    "data-repo-id": "R_kgDOKbDmgw",
    "data-category": "General",
    "data-category-id": "DIC_kwDOKbDmg84CZzPu",
    "data-mapping": "title",
    "data-strict": "1",
    "data-reactions-enabled": "1",
    "data-emit-metadata": "0",
    "data-input-position": "top",
    "data-theme": getGiscusTheme(),
    "data-lang": "en",
    "crossorigin": "anonymous",
    "async": "",
  };

  // Dynamically create script tag
  const giscusScript = document.createElement("script");
  Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
  document.body.appendChild(giscusScript);

  // Update giscus theme when theme switcher is clicked
  const toggle = document.querySelector('.quarto-color-scheme-toggle');
  if (toggle) {
    toggle.addEventListener('click', setGiscusTheme);
  }
});
  
</script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../posts/index.html"> 
<span class="menu-text">Posts</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Introductory voice analytics with R</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">R</div>
                <div class="quarto-category">voice analytics</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 7, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#voice-analytics-decoding-the-vocal-spectrum" id="toc-voice-analytics-decoding-the-vocal-spectrum" class="nav-link active" data-scroll-target="#voice-analytics-decoding-the-vocal-spectrum">Voice analytics: Decoding the vocal spectrum</a></li>
  <li><a href="#the-analytical-process-from-acquisition-to-statistical-analysis" id="toc-the-analytical-process-from-acquisition-to-statistical-analysis" class="nav-link" data-scroll-target="#the-analytical-process-from-acquisition-to-statistical-analysis">The analytical process: From acquisition to statistical analysis</a></li>
  <li><a href="#understanding-user-frustration" id="toc-understanding-user-frustration" class="nav-link" data-scroll-target="#understanding-user-frustration">Understanding user frustration</a></li>
  <li><a href="#data-acquisition-and-processing" id="toc-data-acquisition-and-processing" class="nav-link" data-scroll-target="#data-acquisition-and-processing">Data acquisition and processing</a>
  <ul class="collapse">
  <li><a href="#data-acquisition" id="toc-data-acquisition" class="nav-link" data-scroll-target="#data-acquisition">Data acquisition</a></li>
  <li><a href="#reading-sound-files" id="toc-reading-sound-files" class="nav-link" data-scroll-target="#reading-sound-files">Reading sound files</a></li>
  <li><a href="#playing-a-sound-file" id="toc-playing-a-sound-file" class="nav-link" data-scroll-target="#playing-a-sound-file">Playing a sound file</a></li>
  <li><a href="#preprocessing-sound-files" id="toc-preprocessing-sound-files" class="nav-link" data-scroll-target="#preprocessing-sound-files">Preprocessing sound files</a></li>
  <li><a href="#writing-sound-files" id="toc-writing-sound-files" class="nav-link" data-scroll-target="#writing-sound-files">Writing sound files</a></li>
  </ul></li>
  <li><a href="#visualizing-sound" id="toc-visualizing-sound" class="nav-link" data-scroll-target="#visualizing-sound">Visualizing sound</a>
  <ul class="collapse">
  <li><a href="#visualizing-amplitude" id="toc-visualizing-amplitude" class="nav-link" data-scroll-target="#visualizing-amplitude">Visualizing amplitude</a></li>
  <li><a href="#visualizing-fundamental-frequency" id="toc-visualizing-fundamental-frequency" class="nav-link" data-scroll-target="#visualizing-fundamental-frequency">Visualizing fundamental frequency</a></li>
  <li><a href="#spectrograms" id="toc-spectrograms" class="nav-link" data-scroll-target="#spectrograms">Spectrograms</a></li>
  </ul></li>
  <li><a href="#acoustic-feature-extraction" id="toc-acoustic-feature-extraction" class="nav-link" data-scroll-target="#acoustic-feature-extraction">Acoustic feature extraction</a>
  <ul class="collapse">
  <li><a href="#time-associated-characteristics" id="toc-time-associated-characteristics" class="nav-link" data-scroll-target="#time-associated-characteristics">Time associated characteristics</a></li>
  <li><a href="#intensity-associated-characteristics" id="toc-intensity-associated-characteristics" class="nav-link" data-scroll-target="#intensity-associated-characteristics">Intensity associated characteristics</a></li>
  <li><a href="#frequency-associated-characteristics" id="toc-frequency-associated-characteristics" class="nav-link" data-scroll-target="#frequency-associated-characteristics">Frequency associated characteristics</a></li>
  <li><a href="#spectral-associated-characteristics" id="toc-spectral-associated-characteristics" class="nav-link" data-scroll-target="#spectral-associated-characteristics">Spectral associated characteristics</a></li>
  <li><a href="#vocal-features-summary" id="toc-vocal-features-summary" class="nav-link" data-scroll-target="#vocal-features-summary">Vocal features summary</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>Interpersonal communication transcends mere words, incorporating nuanced nonverbal signals where the voice plays a pivotal role. We dynamically adjust our voice to convey emotions, such as happiness or sadness, and intentions, including subtle nuances like sarcasm. We even form impressions from the way someone speaks. Therefore, analyzing not just the content but also the delivery—the voice—is essential for a more comprehensive understanding of communication.</p>
<section id="voice-analytics-decoding-the-vocal-spectrum" class="level2">
<h2 class="anchored" data-anchor-id="voice-analytics-decoding-the-vocal-spectrum">Voice analytics: Decoding the vocal spectrum</h2>
<p>Voice analytics precisely aims to achieve this by examining the voice beyond its linguistic content. Various methods exist for conducting voice analytics, with one of the most common involving the extraction of different characteristics from the voice, known as vocal features. These features include amplitude, correlated with the loudness of a sound, and fundamental frequency, associated with pitch—that is, how high or low we perceive a voice to be. For instance, amplitude provides insights into the volume or intensity of speech, while fundamental frequency helps discern the pitch variations in a speaker’s voice.</p>
</section>
<section id="the-analytical-process-from-acquisition-to-statistical-analysis" class="level2">
<h2 class="anchored" data-anchor-id="the-analytical-process-from-acquisition-to-statistical-analysis">The analytical process: From acquisition to statistical analysis</h2>
<p>However, before delving into the extraction of vocal features, a series of pivotal steps forms an integral part of the analytical process. The initial phase entails the acquisition of voice recordings, achievable through direct recording or retrieval from publicly accessible sources. Once the files are obtained, meticulous processing becomes indispensable, involving the arrangement of metadata and validation of collected files to ensure precision and organizational coherence.</p>
<p>Following this preparatory phase, the subsequent step involves reading and preprocessing the voice files. This encompasses data preprocessing and transformation by primarily eliminating extraneous elements, such as irrelevant utterances and background noise. These preprocessing steps are crucial for ensuring the quality of the data.</p>
<p>After preprocessing the audio files, we can extract the vocal features of interest, such as amplitude and fundamental frequency. These features can subsequently be explored through visualization and the computation of summary statistics to gain a deeper understanding. This exploration may reveal further anomalies, or matters requiring additional processing may be detected. Consequently, we may proceed to further preprocess the audio files. Once the data attains sufficient quality, the process culminates in statistical analysis. In this phase, the extracted vocal features may be compared through statistical tests or used to train prediction models. This whole process is depicted in <a href="#fig-voice-analytics-pipeline" class="quarto-xref">Figure&nbsp;1</a>.</p>
<p>It is imperative to recognize that the process just described here is a simplified abstraction of the voice analytics process. Practical voice analytics is characterized by flexibility and adaptability rather than a rigidly linear progression. This iterative nature accommodates refinements and adjustments, ultimately enhancing the robustness and accuracy of the analytical outcomes.</p>
<div id="fig-voice-analytics-pipeline" class="invertImage quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-voice-analytics-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/voice-analytics-pipeline.png" class="invertImage img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-voice-analytics-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Streamlined view of the voice analytics pipeline
</figcaption>
</figure>
</div>
<p>To illustrate how voice analytics operates in a real-world context, we offer a simple, practical tutorial using R. This tutorial walks you through the fundamental steps of the voice analytics pipeline, from reading audio files to extracting vocal features and drawing basic inferences.</p>
</section>
<section id="understanding-user-frustration" class="level2">
<h2 class="anchored" data-anchor-id="understanding-user-frustration">Understanding user frustration</h2>
<p>In this tutorial, we will analyze a compelling video featuring a female Scottish user attempting, albeit humorously, to issue a command to Amazon Alexa to play a song on Spotify. This viral video, though amusing, highlights a common frustration many users encounter when trying to communicate effectively with voice-controlled interfaces.</p>
<p><video src="assets/alexa_video.mp4" class="img-fluid" controls=""><a href="assets/alexa_video.mp4">Video</a></video></p>
</section>
<section id="data-acquisition-and-processing" class="level2">
<h2 class="anchored" data-anchor-id="data-acquisition-and-processing">Data acquisition and processing</h2>
<section id="data-acquisition" class="level3">
<h3 class="anchored" data-anchor-id="data-acquisition">Data acquisition</h3>
<p>For our comprehensive analysis, we begin by extracting the audio from the previous video and converting it into the Waveform audio file format (WAV). In this scenario, we are interested in two pivotal aspects of this interaction:</p>
<ol type="1">
<li><p><strong>Speech Formation of the wake word “<em>Alexa</em>”</strong></p></li>
<li><p><strong>Vocal Changes During the Issuance of a Command (“<em>Alexa, play something is cooking in my kitchen on Spotify by Dana</em>”)</strong></p></li>
</ol>
<p>To facilitate our analysis, we cropped the voice recordings, retaining only the segments containing the two initial commands, including the wake word “<em>Alexa</em>”. In the first command, the speaker calmly requests Alexa to play a song. However, it becomes apparent that Alexa doesn’t comprehend the given command. Consequently, the speaker repeats the same command with a noticeable tone of frustration.</p>
<p>Our following sections will delve into a detailed examination of this particular case, untangling the distinctions between these two commands that lead us to perceive frustration from the user’s perspective. You can download the files for this example by clicking the following button.</p>
<div class="button_container">
<form method="get" action="assets/alexa_recording/alexa_recordings.zip">
<button type="submit" class="download_button">
<p>Download</p>
</button>
</form>
</div>
<p>Our analytical approach primarily leverages the <code>seewave</code> package, which has emerged as the gold standard in R-sound analysis. This versatile package encompasses an impressive array of 130 functions designed for the analysis, manipulation, representation, editing, and synthesis of time-based audio waveforms. While seewave serves as our cornerstone, we also make reference to other valuable packages, such as <code>tuneR</code>, <code>soundgen</code>, and <code>phonTools</code>, for their specialized functionalities as needed.</p>
</section>
<section id="reading-sound-files" class="level3">
<h3 class="anchored" data-anchor-id="reading-sound-files">Reading sound files</h3>
<p>As previously mentioned, the primary focus of this tutorial centers around the utilization of the <code>seewave</code> package. While it is important to note that <code>seewave</code> lacks native capabilities for sound file reading, we adeptly overcome this limitation by harnessing functions from complementary packages. It is important to emphasize that some packages may use distinct classes for sound objects. Consequently, when choosing an alternative package to load sound data, it becomes paramount to consider this inherent class compatibility.</p>
<p>In the context of <code>seewave</code>, its core functionalities are tailored to work with sound objects of the <code>Wave</code> class. These <code>Wave</code> class sound objects are conventionally created using the <code>tuneR</code> package. Hence, when working with <code>seewave</code>, it is strongly recommended to employ <code>tuneR</code> for sound data loading.</p>
<p>To load the two user commands including the wake word from the interaction with Amazon Alexa, we use the <code>readWave()</code> function from the <code>tuneR</code> package. This function loads or reads a sound file from a specified location, which we need to pass as its main argument. Additionally, we assign the resulting outputs from reading the two commands to two objects called <code>cmd1</code> and <code>cmd2</code>, as shown below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tuneR)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>cmd1 <span class="ot">&lt;-</span> <span class="fu">readWave</span>(<span class="st">"alexa_cmd1.wav"</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>cmd2 <span class="ot">&lt;-</span> <span class="fu">readWave</span>(<span class="st">"alexa_cmd2.wav"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After loading these two recordings into R, we can call them to obtain an informative output showing several basic characteristics of these recordings. These characteristics encompass:</p>
<ol type="1">
<li><p><strong>Number of Samples</strong>: This indicates the total count of discrete data points in the audio waveform.</p></li>
<li><p><strong>Duration (in seconds)</strong>: The elapsed time in seconds, capturing the length of the audio.</p></li>
<li><p><strong>Sampling Rate (in Hertz)</strong>: Denoting the rate at which individual samples are taken per second.</p></li>
<li><p><strong>Number of Channels</strong>: It signifies whether the audio is mono (single channel) or stereo (two channels).</p></li>
<li><p><strong>Bit Rate</strong>: Representing the number of bits processed per unit of time.</p></li>
</ol>
<p>Below we can see the output for the <code>cmd1</code> and <code>cmd2</code> objects:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>cmd1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Wave Object
    Number of Samples:      335789
    Duration (seconds):     7.61
    Samplingrate (Hertz):   44100
    Channels (Mono/Stereo): Stereo
    PCM (integer format):   TRUE
    Bit (8/16/24/32/64):    16 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>cmd2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Wave Object
    Number of Samples:      368128
    Duration (seconds):     8.35
    Samplingrate (Hertz):   44100
    Channels (Mono/Stereo): Stereo
    PCM (integer format):   TRUE
    Bit (8/16/24/32/64):    16 </code></pre>
</div>
</div>
<p>Upon inspecting this information, it becomes evident that both recordings share identical sampling rates, channel numbers, and bit rates. However, the second recording is 0.74 seconds longer than the first.</p>
<p>Moreover, the <code>readWave()</code> function provides additional optional arguments to enhance control over file reading. Notably, the <code>from</code> and <code>to</code> arguments enable users to selectively read specific segments of the audio file. By default, these arguments operate in sample units, defining the segment based on sample counts. However, the <code>readWave()</code> function introduces the <code>units</code> argument, allowing users to customize the units of the from and to arguments to seconds, minutes, or hours.</p>
<p>To illustrate, suppose we aim to extract two segments from the first command, denoted as <code>cmd1.s1</code> and <code>cmd1.s2</code>. The first segment covers the initial 0.5 seconds of the recording, while the second spans from that point to 2 seconds. This can be accomplished by directly using the <code>readWave()</code> function and specifying the <code>from</code>, <code>to</code>, and <code>units</code> arguments, as shown below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>(cmd1.s1 <span class="ot">&lt;-</span> <span class="fu">readWave</span>(<span class="st">"alexa_cmd1.wav"</span>,<span class="at">from=</span><span class="dv">0</span>,<span class="at">to=</span><span class="fl">0.5</span>,<span class="at">units=</span><span class="st">"seconds"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Wave Object
    Number of Samples:      22050
    Duration (seconds):     0.5
    Samplingrate (Hertz):   44100
    Channels (Mono/Stereo): Stereo
    PCM (integer format):   TRUE
    Bit (8/16/24/32/64):    16 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>(cmd1.s2 <span class="ot">&lt;-</span> <span class="fu">readWave</span>(<span class="st">"alexa_cmd1.wav"</span>,<span class="at">from=</span><span class="fl">0.5</span>,<span class="at">to=</span><span class="dv">2</span>,<span class="at">units=</span><span class="st">"seconds"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Wave Object
    Number of Samples:      66150
    Duration (seconds):     1.5
    Samplingrate (Hertz):   44100
    Channels (Mono/Stereo): Stereo
    PCM (integer format):   TRUE
    Bit (8/16/24/32/64):    16 </code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Wrapping the code in parentheses triggers automatic printing.</p>
</div>
</div>
</section>
<section id="playing-a-sound-file" class="level3">
<h3 class="anchored" data-anchor-id="playing-a-sound-file">Playing a sound file</h3>
<p>Something that we may need at several points of the voice analytics pipeline is to play the recordings/processed recordings, as an additional way to inspect it. Although, R itself cannot play sound files the <code>seewave</code>’s <code>listen()</code> function allows us to call the default audio player of the user’s operating system from R to play the selected audio.</p>
<p>To do so, we first load the <code>seewave</code> package:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(seewave)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, you can employ the <code>listen()</code> function to play audio, for instance, to play the sound recorded in <code>cmd1</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">listen</span>(cmd1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<audio controls="">
<source src="assets/alexa_recording/alexa_cmd1.wav" type="audio/ogg">
</audio>
<p>We could do the same for the second command:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">listen</span>(cmd2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<audio controls="">
<source src="assets/alexa_recording/alexa_cmd2.wav" type="audio/mpeg">
</audio>
<p>Both commands convey identical content but with a slight variation in order. In the first command, the speaker instructs: “<em>Alexa, play ‘Something Is Cooking in My Kitchen’ on Spotify by Dana</em>”. In contrast, the second command the speaker says: “<em>Alexa, play ‘Something Is Cooking in My Kitchen’ by Dana on my Spotify</em>”.</p>
<p>Similar to the <code>readWave()</code> function, <code>listen()</code> supports the <code>from</code> and <code>to</code> arguments, enabling precise selection of sections for auditory playback. Additionally, it allows us to manipulate the sampling frequency rate through the <code>f</code> argument, altering the speaking rate. You can run the following code to hear the first command (<code>cmd1</code>) with a sampling rate 10% higher and with a sampling rate 10% lower, respectively:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">listen</span>(cmd1, <span class="at">f=</span>cmd1<span class="sc">@</span>samp.rate<span class="sc">*</span><span class="fl">1.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<audio controls="">
<source src="assets/alexa_recording/cmd1_10morespeed.wav" type="audio/mpeg">
</audio>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">listen</span>(cmd1, <span class="at">f=</span>cmd1<span class="sc">@</span>samp.rate<span class="sc">/</span><span class="fl">1.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<audio controls="">
<source src="assets/alexa_recording/cmd1_10lesspeed.wav" type="audio/mpeg">
</audio>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>For convenience, subsequent sections directly include sound players after each processed or newly generated audio without explicitly calling the <code>listen()</code> function. Nevertheless, it is crucial to remember that for playing <code>Wave</code> objects through R, the <code>listen()</code> function must be utilized.</p>
</div>
</div>
</section>
<section id="preprocessing-sound-files" class="level3">
<h3 class="anchored" data-anchor-id="preprocessing-sound-files">Preprocessing sound files</h3>
<p>In many instances, effective preprocessing of diverse voice files is crucial to optimize their overall quality. This preprocessing involves a variety of tasks, such as (1) extracting specific segments of interest from a sound wave, (2) removing selected utterances from a soundwave, (3) trimming periods of silence at the beginning or end of a sound file, (4) filtering out all unvoiced frames from a sound file, and (5) eliminating background noise.</p>
<p>The <code>tuneR</code> and <code>seewave</code> packages provide a comprehensive set of functions designed to address these diverse preprocessing procedures:</p>
<ol type="1">
<li><p><code>extractWave()</code><strong>:</strong> This function facilitates the extraction of desired segments from a soundwave. Users can specify the segments using the <code>from</code> and <code>to</code> arguments, as discussed earlier. The default units for the <code>extractWave()</code> function are samples, but users can adjust this using the <code>xunit</code> argument. Specifically, setting ‘xunit’ to “time” enables the extraction of segments in seconds.</p></li>
<li><p><code>deletew()</code><strong>:</strong> This function removes specific portions from a soundwave. As in the case of <code>extractWave()</code>, users can specify segments using the <code>from</code> and <code>to</code> arguments. Notably, for this function, these values are directly specified in seconds. By default, this function returns a <code>matrix</code>, but we can change the output type to a <code>Wave</code> object by specifying the <code>output</code> argument to <code>"Wave"</code>.</p></li>
<li><p><code>noSilence()</code><strong>:</strong> Particularly useful for removing periods of silence from the beginning and/or end of a sound file. By default, it removes silence periods from both the beginning and end. However, users can modify this behavior using the <code>where</code> argument, specifying <code>"start"</code> to remove only the beginning silent frames or <code>"end"</code> to remove only the end silent frames.</p></li>
<li><p><code>zapsilw()</code><strong>:</strong> This function eliminates all unvoiced frames from a sound file. Users can customize this operation by setting the ‘threshold’ argument, which measures the amplitude threshold (in percent) distinguishing silence from signal. The <code>zapsilw()</code> function also, by default, plots oscillograms for both the original sound file and the modified version (after removing the silent voice frames), providing visual insight into the process. Automatic plotting of oscillograms can be deactivated by setting the <code>plot</code> argument to <code>FALSE</code>. Like other functions within the <code>seewave</code> package, this function returns a <code>matrix</code> by default. However, the output type can be changed to a <code>Wave</code> object specifying the <code>output</code> argument as <code>"Wave"</code>.</p></li>
<li><p><code>rmnoise()</code><strong>:</strong> The <code>rmnoise()</code> function effectively eliminates background noise from a sound file through smoothing. Like other functions within the <code>seewave</code> package, this function returns a <code>matrix</code> by default. However, the output type can be changed to a <code>Wave</code> object specifying the <code>output</code> argument as <code>"Wave"</code>.</p></li>
</ol>
<p>These functions allow us to easily manipulate sound files, ensuring they are tailored to meet the specific requirements of the analyses. To illustrate their practical utility, let’s delve into some illustrative examples.</p>
<section id="using-the-extractwave-function" class="level4">
<h4 class="anchored" data-anchor-id="using-the-extractwave-function">Using the <code>extractWave()</code> function</h4>
<p>For example, let’s employ the <code>extractWave()</code> function to isolate a specific segment from the first command which we assigned to the <code>cmd1</code> object. Suppose our goal is to extract the initial 0.8 seconds of that file. To achieve this, we must set four arguments. Initially, the primary argument should be the object of the Wave class, representing the sound file from which we intend to extract a segment. Next, we need to specify the <code>from</code> and <code>to</code> arguments, indicating <code>0</code> and <code>0.8</code>, respectively—indicating the segment we wish to extract spans from <code>0</code> to <code>0.8</code> seconds. It’s essential to note that, by default, these arguments are not expressed in seconds. Consequently, we need to explicitly set the <code>xunit</code> argument to <code>"time"</code> to ensure the units are interpreted as seconds. Otherwise, they would be interpreted as sample units. Therefore, we can extract the first 0.8 seconds from the first command stored in <code>cmd1</code>, which corresponds to the wake word “<em>Alexa</em>”, storing the resulting isolated segment in an object called <code>cmd1.xtr</code>, as demonstrated below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Extract first 700ms</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>cmd1.xtr <span class="ot">&lt;-</span> <span class="fu">extractWave</span>(cmd1, <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="fl">0.8</span>, <span class="at">xunit =</span> <span class="st">"time"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<audio controls="">
<source src="assets/alexa_recording/cmd1_xtr.wav" type="audio/ogg">
</audio>
</section>
<section id="using-the-deletew-function" class="level4">
<h4 class="anchored" data-anchor-id="using-the-deletew-function">Using the <code>deletew()</code> function</h4>
<p>Alternatively, rather than extracting this segment, we can adopt the opposite strategy: removing this segment. This task is easily accomplished using the <code>deletew()</code> function. The arguments required for this operation are quite similar to the previous ones, with the distinction that there’s no need to specify an <code>xunit</code> argument, as the units are already in seconds (and cannot be changed). However, it is essential to specify an <code>output</code> argument to obtain an output of the <code>Wave</code> class. Consequently, we can create a new <code>Wave</code> object that excludes the first 0.8 seconds from the initial command, i.e., excluding the wake word “<em>Alexa</em>”, storing the output into <code>cmd1.rem</code> in the following manner:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Delete first 800ms</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>cmd1.rem <span class="ot">&lt;-</span> <span class="fu">deletew</span>(cmd1, <span class="at">from=</span><span class="dv">0</span>, <span class="at">to=</span><span class="fl">0.8</span>, <span class="at">output=</span><span class="st">"Wave"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<audio controls="">
<source src="assets/alexa_recording/cmd1_rem.wav" type="audio/mpeg">
</audio>
</section>
<section id="using-the-nosilence-function" class="level4">
<h4 class="anchored" data-anchor-id="using-the-nosilence-function">Using the <code>noSilence()</code> function</h4>
<p>Thus far, we have delved into the extraction and deletion of specific audio segments defined by a time frame. However, there are scenarios where our interest lies in removing segments that meet specific conditions, such as unvoiced segments at the outset and conclusion of an audio file. This practice is frequently employed to standardize audio files, as variations in the length of unvoiced frames at the start and end may not necessarily be linked to speaker pauses but could be influenced by other factors. For instance, this variability could be attributed to the individual recording, taking additional time to instruct the speaker to commence or conclude their speech, or to manage the recording process after the speaker has concluded.</p>
<p>To accomplish this, we can use the <code>noSilence()</code> function. Therefore, if we wish to eliminate the initial and end unvoiced frames of the initial command, stored in cmd1, and store the output in a new object called <code>cmd1.cut</code>, we can achieve this with the following code:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Remove only unvoiced start and ending</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>cmd1.cut <span class="ot">&lt;-</span> <span class="fu">noSilence</span>(cmd1, <span class="at">level =</span> <span class="dv">350</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>It is important to highlight that we define a argument called <code>level</code> with a value of <code>350</code>. This argument determines the amplitude level below which samples are considered unvoiced and subsequently removed. BBy default, this value is initialized to zero, which proves overly restrictive in our context. This default setting would result in the detection of no unvoiced areas, given the presence of background noise at the end of the audio, despite these areas being unvoiced.</p>
<p>To address this limitation, we choose a much higher value, specifically 350. This value is carefully selected to be sufficiently elevated to avoid removing voiced areas while effectively identifying and removing unvoiced segments. After running the previous code, we proceed to compare the original and processed commands:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>cmd1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Wave Object
    Number of Samples:      335789
    Duration (seconds):     7.61
    Samplingrate (Hertz):   44100
    Channels (Mono/Stereo): Stereo
    PCM (integer format):   TRUE
    Bit (8/16/24/32/64):    16 </code></pre>
</div>
</div>
<audio controls="">
<source src="assets/alexa_recording/alexa_cmd1.wav" type="audio/ogg">
</audio>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>cmd1.cut</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Wave Object
    Number of Samples:      305734
    Duration (seconds):     6.93
    Samplingrate (Hertz):   44100
    Channels (Mono/Stereo): Stereo
    PCM (integer format):   TRUE
    Bit (8/16/24/32/64):    16 </code></pre>
</div>
</div>
<audio controls="">
<source src="assets/alexa_recording/cmd1_cut.wav" type="audio/ogg">
</audio>
<p>Upon comparing both audio files, we can observe that the processed version is slightly shorter, specifically by 0.68 seconds, compared to the original command. Additionally, when listening to both audios, we can discern that the content of the audio has been effectively preserved in the processed version.</p>
</section>
<section id="using-the-zapsilw-function" class="level4">
<h4 class="anchored" data-anchor-id="using-the-zapsilw-function">Using the <code>zapsilw()</code> function</h4>
<p>Alternatively, we could eliminate all the unvoiced frames—not only those at the start and end but across all segments—of the first command (<code>cmd1</code>) using the <code>zapsilw()</code> function, as shown below:</p>
<div class="cell invertImage">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Remove all unvoiced frames of a soundwave</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>cmd1.nosil <span class="ot">&lt;-</span> <span class="fu">zapsilw</span>(cmd1, <span class="at">output=</span><span class="st">"Wave"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-oscillogram-before-after-silence-removal" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-oscillogram-before-after-silence-removal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-oscillogram-before-after-silence-removal-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-oscillogram-before-after-silence-removal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Oscillogram comparison: original (top) vs.&nbsp;processed first command recording with unvoiced frames removed using default zapsilw() parameters (bottom)
</figcaption>
</figure>
</div>
</div>
</div>
<p>By default, the <code>zapsilw()</code> function generates an oscillogram that compares the original sound recording with its processed counterpart, exemplified in <span class="invertImage"><a href="#fig-oscillogram-before-after-silence-removal" class="quarto-xref">Figure&nbsp;2</a></span>. By comparing both oscillograms we can see how unvoiced frames have been removed, characterized by minimal or absent amplitude. Furthermore, for a comprehensive analysis, the characteristics of both audio files can be compared by calling <code>cmd1</code> and <code>cmd1.nosil</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>cmd1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Wave Object
    Number of Samples:      335789
    Duration (seconds):     7.61
    Samplingrate (Hertz):   44100
    Channels (Mono/Stereo): Stereo
    PCM (integer format):   TRUE
    Bit (8/16/24/32/64):    16 </code></pre>
</div>
</div>
<audio controls="">
<source src="assets/alexa_recording/alexa_cmd1.wav" type="audio/ogg">
</audio>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>cmd1.nosil</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Wave Object
    Number of Samples:      101647
    Duration (seconds):     2.3
    Samplingrate (Hertz):   44100
    Channels (Mono/Stereo): Mono
    PCM (integer format):   TRUE
    Bit (8/16/24/32/64):    16 </code></pre>
</div>
</div>
<audio controls="">
<source src="assets/alexa_recording/cmd1_nosil.wav" type="audio/ogg">
</audio>
<p>When we look at the two files and compare their features, we can see that removing the unvoiced frames (<code>cmd1.nosil</code>) results in a reduction in both the number of samples and the recording duration. The original first command lasts for 7.61 seconds, whereas the processed command, with unvoiced frames removed, is much shorter, specifically having a duration of 2.30 seconds. In simpler terms, this means that 5.31 seconds, which corresponds to the unvoiced frames, have been effectively removed during the process. However, upon listening to <code>cmd1.nosil</code>, it becomes evident that the audio is now nearly incomprehensible. This is because the <code>zapsilw()</code> function removed frames that weren’t strictly unvoiced but had a significantly lower amplitude compared to the majority of voiced frames. The <code>zapsilw()</code> function includes an additional argument, the <code>threshold</code>, aimed at determining what qualifies as an unvoiced frame. The default threshold is 5% (<code>5</code>). Since the current threshold value resulted in the removal of an excessive number of frames for our specific case, let’s investigate the effects of adopting a much lower value, such as 0.3% (<code>0.3</code>):</p>
<div class="cell invertImage">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>cmd1.nosil2 <span class="ot">&lt;-</span> <span class="fu">zapsilw</span>(cmd1, <span class="at">threshold=</span><span class="fl">0.3</span>, <span class="at">output=</span><span class="st">"Wave"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-oscillogram-before-after-silence-removal-threshold-03" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-oscillogram-before-after-silence-removal-threshold-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-oscillogram-before-after-silence-removal-threshold-03-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-oscillogram-before-after-silence-removal-threshold-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Oscillogram comparison: original (top) vs.&nbsp;processed first command recording with unvoiced frames removed using threshold parameter equal to 0.3 (bottom)
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>cmd1.nosil2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Wave Object
    Number of Samples:      257922
    Duration (seconds):     5.85
    Samplingrate (Hertz):   44100
    Channels (Mono/Stereo): Mono
    PCM (integer format):   TRUE
    Bit (8/16/24/32/64):    16 </code></pre>
</div>
</div>
<audio controls="">
<source src="assets/alexa_recording/cmd1_nosil2.wav" type="audio/mpeg">
</audio>
<p>As observed, the processed audio file is now longer than in the previous (5.85 vs 2.30 seconds), reflecting a decrease in the number of frames identified as unvoiced. Additionally, upon listening, the processed audio exhibits a more natural sound compared to the previous version. It’s worth noting that, while it may not replicate the exact naturalness of the original, this deviation is common. Humans naturally introduce pauses and breaks in speech, and the removal of unvoiced frames can contribute to this altered perception.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Defining function arguments">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Defining function arguments
</div>
</div>
<div class="callout-body-container callout-body">
<p>The choice of preprocessing function arguments, which influence the behavior of the function, is a deliberate and thoughtful process. When establishing these parameters, we typically engage in an iterative approach. This involves listening to the resulting audio and visualizing it to ensure that the outcome aligns with our desired specifications. Although we refrain from explicitly illustrating this iterative process to maintain the clarity of this post, it’s essential to acknowledge its presence.</p>
<p>It’s important to recognize that determining the appropriate values for these arguments during file preprocessing is not a straightforward task. Instead, it demands careful consideration and may involve multiple iterations to arrive at the optimal values. This underscores the significance of a meticulous and thoughtful approach when fine-tuning these parameters to achieve the desired results.</p>
</div>
</div>
<p>It’s essential to consider that the decision to remove all unvoiced breaks should align with our analytical goals. If our aim is to analyze or extract information from the breaks and their duration, it might be preferable to solely eliminate unvoiced frames from the beginning and end of the recording using the <code>noSilence()</code> function instead of the <code>zapsilw()</code> function.</p>
</section>
<section id="using-the-rmnoise-function" class="level4">
<h4 class="anchored" data-anchor-id="using-the-rmnoise-function">Using the <code>rmnoise()</code> function</h4>
<p>To improve audio quality, we take additional steps beyond eliminating unvoiced frames. We enhance the quality further by utilizing the <code>rmnoise()</code> function to reduce background noise, as in this audio clip, you can clearly hear a disturbance that sounds like a metal object, most likely a teaspoon, hitting a glass or a cup.</p>
<p>Recognizing that breaks in audio can offer insights into user frustration, we focus on using the processed version of the command—<code>cmd1.cut</code>—where we have only removed unvoiced frames from the start and the end, instead of using the version in which we removed all the unvoiced frames.</p>
<p>It’s important to highlight that in this specific scenario, we must explicitly set the output argument as <code>"Wave"</code> when using the <code>rmnoise()</code> function to obtain a <code>Wave</code> object. Otherwise, the output would be in the <code>matrix</code> format. Additionally, we fine-tuned the noise reduction process by adjusting the <code>spar</code> argument. This parameter essentially governs the extent of noise reduction—higher values lead to less audible background noise. However, it’s essential to be cautious since increasing the spar value not only diminishes background noise but also introduces a trade-off, potentially altering other parts of the audio. The <code>spar</code> argument typically takes values between 0 and 1, but it can also take other values. In this case, since the background noise is quite prominent, we proceed to set a <code>spar</code> value equal to <code>1.15</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove noise</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>cmd1.nonoise <span class="ot">&lt;-</span> <span class="fu">rmnoise</span>(cmd1.cut, <span class="at">output =</span> <span class="st">"Wave"</span>, <span class="at">spar =</span> <span class="fl">1.15</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<audio controls="">
<source src="assets/alexa_recording/cmd1_nonoise.wav" type="audio/mpeg">
</audio>
<p>Upon listening, it’s evident that the <code>rmnoise()</code> function effectively reduced the volume of the background noise— the metallic sound resembling an object striking a glass or cup—although traces of that sound persist. However, the heightened value of the spar argument in the <code>rmnoise()</code> function slightly impacted the overall audio quality. To address this, we employ additional functions to further minimize the noise and enhance audio quality:</p>
<ol type="1">
<li><p>Initially, we apply the <code>afilter()</code> function, designed to eliminate signals with amplitudes below a specified threshold. The objective is to target the background noise, which now has a significantly lower amplitude compared to the rest of the audio. We control the threshold using the threshold argument, setting it to a low value, specifically <code>0.075</code>.</p></li>
<li><p>Subsequently, having applied the <code>afilter()</code> function, we revisit the <code>rmnoise()</code> function, this time with a reduced spar value of <code>0.75</code>. With this step, we ensure thorough noise removal.</p></li>
<li><p>Finally, we use the <code>preemphasis()</code> function, which amplifies high-frequency content in the sample. Given that we have either completely or nearly eliminated the background noise, we emphasize the high-frequency content that may have downplayed by earlier functions. This strategic emphasis aims to enhance the quality of the remaining sound.</p></li>
</ol>
<p>We store the resulting processed audio in a new object called cmd1.filtered. The code for all the mentioned steps is provided below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>cmd1.filtered <span class="ot">&lt;-</span> <span class="fu">afilter</span>(cmd1.nonoise, <span class="at">output =</span> <span class="st">"Wave"</span>, <span class="at">threshold =</span> <span class="fl">0.075</span>, <span class="at">plot =</span> <span class="cn">FALSE</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>cmd1.filtered <span class="ot">&lt;-</span> <span class="fu">rmnoise</span>(cmd1.filtered, <span class="at">output =</span> <span class="st">"Wave"</span>, <span class="at">spar =</span> <span class="fl">0.75</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>cmd1.filtered <span class="ot">&lt;-</span> <span class="fu">preemphasis</span>(cmd1.filtered, <span class="at">alpha =</span> <span class="fl">0.975</span>, <span class="at">output =</span> <span class="st">"Wave"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<audio controls="">
<source src="assets/alexa_recording/cmd1_filtered.wav" type="audio/ogg">
</audio>
<p>As we can tell, the voice quality has significantly improved now. While there’s still a bit of background noise, it’s notably reduced compared to the original audio.</p>
</section>
<section id="preprocessing-the-second-command" class="level4">
<h4 class="anchored" data-anchor-id="preprocessing-the-second-command">Preprocessing the second command</h4>
<p>After completing the preprocessing for the initial command, we proceed to apply the same preprocessing steps for the second command in this way to have fair comparisons of audio files (as with the preprocessing we manipulate some of the features of the audio file).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Remove only unvoiced start and ending. In this case, we use a parameter level equal to 800, as there's some background noise at the start and at the end. In this way, we can cut these areas.</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>cmd2.cut <span class="ot">&lt;-</span> <span class="fu">noSilence</span>(cmd2, <span class="at">level =</span> <span class="dv">800</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Remove noise</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>cmd2.nonoise <span class="ot">&lt;-</span> <span class="fu">rmnoise</span>(cmd2.cut, <span class="at">output =</span> <span class="st">"Wave"</span>, <span class="at">spar =</span> <span class="fl">1.15</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>cmd2.filtered <span class="ot">&lt;-</span> <span class="fu">afilter</span>(cmd2.nonoise, <span class="at">output =</span> <span class="st">"Wave"</span>, <span class="at">threshold =</span> <span class="fl">0.075</span>, <span class="at">plot =</span> <span class="cn">FALSE</span>)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>cmd2.filtered <span class="ot">&lt;-</span> <span class="fu">rmnoise</span>(cmd2.filtered, <span class="at">output =</span> <span class="st">"Wave"</span>, <span class="at">spar =</span> <span class="fl">0.75</span>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>cmd2.filtered <span class="ot">&lt;-</span> <span class="fu">preemphasis</span>(cmd2.filtered, <span class="at">alpha =</span> <span class="fl">0.975</span>, <span class="at">output =</span> <span class="st">"Wave"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<audio controls="">
<source src="assets/alexa_recording/cmd2_filtered.wav" type="audio/ogg">
</audio>
</section>
</section>
<section id="writing-sound-files" class="level3">
<h3 class="anchored" data-anchor-id="writing-sound-files">Writing sound files</h3>
<p>Once you’ve made adjustments or enhancements to a sound file, preserving the edited version for future use is essential. The <code>seewave</code> package makes this process easy through <code>savewav()</code> function, specifically designed for saving R sound objects as .wav files. To utilize this function effectively, you’ll need to specify three crucial arguments:</p>
<ol type="1">
<li><p><strong>R Sound Object (</strong><code>wave</code><strong>):</strong> R object you want to save as a .wav file.</p></li>
<li><p><strong>Sampling Frequency (</strong><code>f</code><strong>):</strong> Sampling frequency for the saved .wav file. If the R object you want to save is of the <code>Wave</code> type, there’s no need to specify such argument.</p></li>
<li><p><strong>Filename (</strong><code>filename</code><strong>):</strong> Name under which the edited sound object will be saved.</p></li>
</ol>
<p>As a practical example, let’s save the background noise-free version of cmd1 and cmd2 (<code>cmd1.filtered</code>, and <code>cmd2.filtered</code>) as .wav files named cmd1_filtered.wav and cmd2_filtered.wav, respectively, within our system.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">savewav</span>(cmd1.filtered, <span class="at">filename =</span> <span class="st">"cmd1_filtered.wav"</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">savewav</span>(cmd2.filtered, <span class="at">filename =</span> <span class="st">"cmd2_filtered.wav"</span>)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="visualizing-sound" class="level2">
<h2 class="anchored" data-anchor-id="visualizing-sound">Visualizing sound</h2>
<p>After addressing the stages of reading, editing, and saving sound objects, our next step involves visualizing the characteristics of a sound wave. Visualization serves as the process of translating a sound wave into a graphical representation. The key aspects typically depicted in a sound wave visualization are its (1) amplitude, (2) frequency, and (3) a combination of the previous two. All of them are usually illustrated against time.</p>
<p>The primary visualizations employed for this purpose are:</p>
<ul>
<li><p><strong>Oscillograms:</strong> These representations focus on capturing amplitude variations, providing a visual insight into the intensity or strength of the sound wave at different points in time.</p></li>
<li><p><strong>Spectrograms:</strong> This type of visualization offers a comprehensive view of both frequency and the dynamic relationship between frequency and amplitude over time.</p></li>
</ul>
<p>It is important to highlight that, in this context, our progression directly shifts to visualization without the intermediary step of feature extraction, as depicted in <a href="#fig-voice-analytics-pipeline" class="quarto-xref">Figure&nbsp;1</a>. This decision is motivated, in part, by the inherent capability of the visualization functions to directly extract the pertinent features prior to their visualization.</p>
<section id="visualizing-amplitude" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-amplitude">Visualizing amplitude</h3>
<div class="callout callout-style-default callout-tip callout-titled" title="Amplitude">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Amplitude
</div>
</div>
<div class="callout-body-container callout-body">
<p>Amplitude quantifies the extent of a wave’s displacement from its average value. In the context of sound, it specifically denotes the degree to which air particles deviate from their equilibrium position. Amplitude serves as a key factor in determining the strength or loudness of a sound and is expressed in decibels (dB).</p>
</div>
</div>
<p>Oscillograms offer a visual representation of the amplitude of a soundwave plotted against time. They are often referred to as waveforms, as they graphically depict the variations within the sound wave itself. Oscillograms serve as valuable tools for discerning potential changes in loudness over time within a soundwave. In R, you can create oscillograms using the <code>oscillo()</code> function from the <code>seewave</code> package. This function requires just one argument, the sound object. Moreover, <code>oscillo()</code> provides the flexibility to customize various visual aspects, such as the title (using the <code>title</code> argument), label color (via the <code>collab</code> argument), and wave color (by setting the <code>colwave</code> argument). Additionally, you can specify the <code>from</code> and <code>to</code> arguments, similar to what we did during data processing, to generate an oscillogram for a specific time interval in seconds.</p>
<p>To gain insights from the oscillograms of the two Alexa commands, we aim to first visualize the entire soundwave including the wake word (<code>cmd1</code> and <code>cmd2</code>) and then zoom in to focus solely on the articulation of the wake word.</p>
<p>To consolidate all four graphs within a unified plotting area, we employ the standard <code>par</code> and <code>mfrow</code> arguments in R, partitioning the plot into four distinct sections. For an exclusive display of the wake word, the <code>from</code> and <code>to</code> arguments within the <code>oscillo()</code> function are utilized. Additionally, we utilize the <code>colwave</code> argument to distinguish the entire command plots in black and the isolated wake words in blue. We set automatic titles for the oscillograms by enabling the <code>title</code> argument to be <code>TRUE</code> for the complete commands, providing information on total time and sampling rate. For the wake words, we actively set a custom title by specifying the desired text in this argument.</p>
<p>To enhance differentiation between whole command and isolated wake word plots, we go a step further and adjust their axis label colors to red, setting the <code>collab</code> argument to red. The complete code is provided below:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">General view</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Detailed view of commands 1 and 2</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell invertImage" data-warnings="false">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="fu">oscillo</span>(cmd1.filtered, <span class="at">colwave=</span><span class="st">"black"</span>, <span class="at">collab=</span><span class="st">"black"</span>, <span class="at">title =</span> <span class="cn">TRUE</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="fu">oscillo</span>(cmd2.filtered, <span class="at">colwave=</span><span class="st">"black"</span>, <span class="at">collab=</span><span class="st">"black"</span>, <span class="at">title =</span> <span class="cn">TRUE</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="fu">oscillo</span>(cmd1.filtered, <span class="at">from=</span><span class="dv">0</span>, <span class="at">to=</span>.<span class="dv">7</span>, <span class="at">colwave=</span><span class="st">"blue"</span>, <span class="at">collab=</span><span class="st">"red"</span>, </span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>             <span class="at">title =</span> <span class="st">"First     Command - wake word Only"</span>)</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="fu">oscillo</span>(cmd2.filtered, <span class="at">from=</span><span class="dv">0</span>, <span class="at">to=</span>.<span class="dv">7</span>, <span class="at">colwave=</span><span class="st">"blue"</span>, <span class="at">collab=</span><span class="st">"red"</span>, </span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>             <span class="at">title =</span> <span class="st">"Second Command - wake word Only"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-oscillograms" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-oscillograms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-oscillograms-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-oscillograms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Oscillograms for the first and second command, including the wake word (upper panel, colored in black) and isolated wake words (lower panel, colored in blue)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div id="fig-detailed-oscillogram-cmd1" class="invertImage quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-detailed-oscillogram-cmd1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/Oscillogram_command1_detailed.png" class="invertImage img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-detailed-oscillogram-cmd1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Detailed view of the oscillogram for the first command, including the wake word
</figcaption>
</figure>
</div>
<div id="fig-detailed-oscillogram-cmd2" class="invertImage quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-detailed-oscillogram-cmd2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/Oscillogram_command2_detailed.png" class="invertImage img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-detailed-oscillogram-cmd2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Detailed view of the oscillogram for the second command, including the wake word
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>In addition to the oscillograms we just created, which are presented in <span class="invertImage"><a href="#fig-oscillograms" class="quarto-xref">Figure&nbsp;4</a></span>. We have included two additional and separate oscillograms, presenting a detailed view for the initial and second commands, including the wake word. Notably, we adjusted the oscillogram of the initial command to align with the temporal segment of the second command. This adjustment facilitates a direct comparison between the two. Moreover, we have accompanied these two additional oscillograns by textual transcriptions for each utterance. The visual representations of these detailed oscillograms are illustrated in <a href="#fig-detailed-oscillogram-cmd1" class="quarto-xref">Figure&nbsp;5</a> and <a href="#fig-detailed-oscillogram-cmd2" class="quarto-xref">Figure&nbsp;6</a>, respectively, and can be viewed by clicking the “Detailed view of commands 1 and 2” tab.</p>
<p>Upon closer examination of these oscillograms, a few notable observations come to light at first glance:</p>
<ol type="1">
<li><p><strong>Difference in voice breaks</strong>: The first command exhibits a broader voice break between the wake word “<em>Alexa</em>” and the subsequent portion compared to the second command. Following this, the majority of voice breaks are relatively brief. However, in the second command, there is another extended voice break between “<em>by Dana</em>” and “<em>on my Spotify</em>”.</p></li>
<li><p><strong>Emphasis on Individual Words</strong>: The second command exhibits a somewhat clearer distinction between utterances in comparison to the first command. Moreover, discernible variations in the articulation of specific words are observable, as indicated by the distinct shapes of the utterances. For instance, in the first command, the term “<em>on</em>” is accentuated with a higher amplitude, signifying a louder pronunciation in contrast to the second command. Moreover, the wake word “<em>Alexa</em>” reveals disparities between the two commands, with more pronounced “irregularities” in the second command. These irregularities entail fluctuations in amplitude, particularly noticeable when enunciating the initial part of the word.</p></li>
</ol>
</section>
<section id="visualizing-fundamental-frequency" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-fundamental-frequency">Visualizing fundamental frequency</h3>
<div class="callout callout-style-default callout-tip callout-titled" title="Fundamental frequency">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Fundamental frequency
</div>
</div>
<div class="callout-body-container callout-body">
<p>The fundamental frequency (F0) is the lowest frequency present in a waveform, and it determines the perceived pitch of the voice, influencing how sounds are interpreted as high or low. At higher F0 values, the associated sounds are perceived as higher in pitch.</p>
<p>Therefore, it plays a critical role in conveying the tonal and rhythmic properties of speech, being instrumental in transmitting linguistic objectives in speech communication. Additionally, it is intimately tied to gender perception—adult men generally exhibit F0 values ranging from 80 to 175Hz. While adult women typically fall between 160 and 270Hz.</p>
</div>
</div>
<p>In addition to examining amplitude, a crucial aspect involves visualizing the fundamental frequency. This is often represented as a plot of fundamental frequency against time, referred to as an “F0 contour” or “pitch track.”</p>
<p>This visualization yields valuable insights into the linguistic aspect of tone, contributing supplementary information to enrich our comprehension of message delivery. <strong>For the sake of simplicity, we will narrow our focus to the wake word for this visualization and subsequent visualizations</strong>. This decision is based on our previous observations in the oscillograms, where we discerned subtle variations in the shapes of the wake word “<em>Alexa</em>” between the two commands. Consequently, our objective is to delve deeper into understanding the delivery of this specific word, particularly in terms of its tone.</p>
<p>To proceed with this exploration, we employ the <code>extractWave()</code> function to extract the wake words from the first and second commands. Specifically, we focus on the initial 0.7 seconds of both commands, the duration during which (approximately) the wake word is situated. In addition, we use the <code>noSilence()</code> function, to make sure that we did not extract some unvoiced section at the start or at the end. The extracted wake word from the first command is saved as an object named <code>w1</code>, while the wake word from the second command is stored as <code>w2</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>w1 <span class="ot">&lt;-</span> <span class="fu">extractWave</span>(cmd1.filtered, <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> .<span class="dv">7</span>, <span class="at">xunit =</span> <span class="st">"time"</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>w1 <span class="ot">&lt;-</span> <span class="fu">noSilence</span>(w1, <span class="at">level =</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<audio controls="">
<source src="assets/alexa_recording/alexa_wake word1.wav" type="audio/ogg">
</audio>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>w2 <span class="ot">&lt;-</span> <span class="fu">extractWave</span>(cmd2.filtered, <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> .<span class="dv">7</span>, <span class="at">xunit =</span> <span class="st">"time"</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>w2 <span class="ot">&lt;-</span> <span class="fu">noSilence</span>(w2, <span class="at">level =</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<audio controls="">
<source src="assets/alexa_recording/alexa_wake word2.wav" type="audio/ogg">
</audio>
<p>Having isolated the two wake words, the next step involves concatenating them into a single audio file, with the second wake word playing immediately after the first one. This concatenation is achieved using the <code>bind()</code> function from the <code>tuneR</code> package, which seamlessly combines the provided <code>Wave</code> objects:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>(wake_all <span class="ot">&lt;-</span> <span class="fu">bind</span>(w1,w2))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Wave Object
    Number of Samples:      55317
    Duration (seconds):     1.25
    Samplingrate (Hertz):   44100
    Channels (Mono/Stereo): Mono
    PCM (integer format):   TRUE
    Bit (8/16/24/32/64):    16 </code></pre>
</div>
</div>
<audio controls="">
<source src="assets/alexa_recording/wake_all.wav" type="audio/ogg">
</audio>
<p>After combining the two wake words, we utilize the <code>autoc()</code> function of the <code>seewave</code> package on the concatenated sound object, <code>wake_all</code>. This function produces a plot that visualizes the fundamental frequency of the audio object across different time points. Additionally, we specify the <code>ylim</code> parameter to limit the y-axis between 0 and 600 Hz (0.6 KHz). Finally, we add a vertical line using the <code>abline()</code> function, separating the wake words from the first and second commands. The resulting plot from this process is depicted in <span class="invertImage"><a href="#fig-pitch" class="quarto-xref">Figure&nbsp;7</a></span>.</p>
<div class="cell invertImage">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Note: ylim units need to be in KHz</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>F0 <span class="ot">&lt;-</span> <span class="fu">autoc</span>(wake_all, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.6</span>)) </span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co">#We add a separation line, between the wake word 1 and wake word 2</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.635</span>,<span class="at">col=</span><span class="st">"red"</span>,<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">lty=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-pitch" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pitch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-pitch-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pitch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Pitch track for the two wake words
</figcaption>
</figure>
</div>
</div>
</div>
<p>This plot reveals distinct pitch contours for both wake words. In the wake word of the first command, the fundamental frequency remains relatively constant, hovering around 200 Hz (0.2 KHz) for the initial 0.2 seconds. Subsequently, there is some variability for a few seconds before a noticeable increase during the last 0.15 seconds, reaching approximately 300 Hz. Conversely, in the wake word of the second command, the fundamental frequency ascends from 200 Hz (0.2 KHz) to around 300 Hz in the first 0.2 seconds, followed by a subsequent decrease.</p>
<section id="visualizing-formants" class="level4">
<h4 class="anchored" data-anchor-id="visualizing-formants">Visualizing formants</h4>
<p>To enrich our analysis, we proceed to visualize key formants, which are the frequencies that resonate most prominently in human speech. The first three formants, denoted as F1, F2, and F3, are particularly informative. Formants play a pivotal role in discerning distinct vowels, contributing to the nuances of speech sounds.</p>
<p>For formant visualization, we employ the <code>formanttrack()</code> function from the <code>phonTools</code> package. It’s essential to note that the <code>phonTools</code> package exclusively supports mono audio. In our case, since we are dealing with stereo files, we specify only one channel. The channel of a wave object can be accessed using the <code>@</code> operator along with the desired channel name (<code>left</code> or <code>right</code>). Additionally, since <code>phonTools</code> is not specifically tailored for <code>Wave</code> objects, the sampling frequency of the sound file must be manually set using the <code>fs</code> argument. Thus, we proceed to load the <code>phonTools</code> package to plot the first three formants and, then, use the <code>formanttrack()</code> function to the two wake words:</p>
<div class="cell invertImage">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(phonTools)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="fu">formanttrack</span>(w1<span class="sc">@</span>left, <span class="at">fs=</span>w1<span class="sc">@</span>samp.rate, <span class="at">formants=</span><span class="dv">3</span>, <span class="at">periodicity=</span>.<span class="dv">5</span>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="fu">formanttrack</span>(w2<span class="sc">@</span>left, <span class="at">fs=</span>w2<span class="sc">@</span>samp.rate, <span class="at">formants=</span><span class="dv">3</span>, <span class="at">periodicity=</span>.<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-formanttrack" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-formanttrack-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-formanttrack-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-formanttrack-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: <span style="color:#000000; font-weight:600">First</span>, <span style="color:#df536b; font-weight:600">second</span> ,and <span style="color:#61d04f; font-weight:600">third</span> formant tracks for the two wake words associated with the first (left panel) and second (right panel) commands
</figcaption>
</figure>
</div>
</div>
</div>
<p>In <span class="invertImage"><a href="#fig-formanttrack" class="quarto-xref">Figure&nbsp;8</a></span>, we can see the first three formants for each wake word represented by different colors. By scrutinizing the formant tracks of the wake words in both commands, discernible distinctions emerge, offering insights into the speaker’s tone and emotional disposition.</p>
<p>In dissecting the first command’s wake word, we observe a more tightly spaced and evenly distributed set of formant frequencies compared to the second command’s wake word. This discrepancy implies a composed and relaxed speech pattern for the first command’s wake word than for the second, which exhibits greater variability, hinting at heightened tension and force in the speaker’s voice—reflecting the speaker frustration.</p>
<p>Digging deeper into the analysis, the higher first formant frequency (F1) in the second command’s wake word suggests a wider mouth opening or an elevated tongue position, contributing to a more resonant and forceful vocal delivery. Similarly, the elevated second formant frequency (F2) in the second command’s formant track points to lip rounding or vocal tract narrowing, characteristics associated with increased vocal strength.</p>
<p>Of particular note is the less pronounced third formant frequency (F3) in the second command’s wake word, indicating a degree of vocal tract constriction. While this intensifies the voice, it may also impart a muffled or harsh quality.</p>
<p>In summary, the formant tracks strongly imply that the speaker imparts greater force and tension in the second command, highlighting the undercurrent of frustration. Recognizing these discernible patterns in vocal intensity and tension enriches our understanding of the speaker’s emotional state and demeanor.</p>
</section>
</section>
<section id="spectrograms" class="level3">
<h3 class="anchored" data-anchor-id="spectrograms">Spectrograms</h3>
<p>Spectrograms offer a detailed, multidimensional representation of a soundwave, representing time along the x-axis, frequency along the y-axis, and amplitude levels (loudness) through varying color codes. They are specially useful for detecting audio problems by sight.</p>
<p>The <code>seewave</code> package provides the <code>spectro()</code> function, allowing us to easily create spectrograms. When using this function, you only need a <code>Wave</code> object as input. However, there are optional parameters that allow you to customize the appearance of the spectrogram. For instance, the <code>flim</code> argument allows the specification of minimum and maximum frequencies displayed, andthe <code>osc</code> parameter introduces an oscillogram at the bottom of the spectrogram plot.</p>
<p>The default color scheme in the <code>spectro()</code> function is relative, utilizing <span class="dark-span">cyan</span><span class="light-span">red</span> for regions with the highest amplitude in comparison to the entire audio representation, with all other colors relative to that maximum value. As a result, for an accurate comparison between the two wake words, rather than creating separate spectrograms for each, we will generate a unified spectrogram for the binned wake words (<code>wake_all</code>). Furthermore, we add a vertical line separating both wake words by using the <code>abline()</code> function:</p>
<div class="cell invertImage">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">spectro</span>(wake_all, <span class="at">osc=</span><span class="cn">TRUE</span>, <span class="at">flim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">1.5</span>))</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.62</span>,<span class="at">col=</span><span class="st">"red"</span>,<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">lty=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-spectrograms" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spectrograms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-spectrograms-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spectrograms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Spectrogram for the wake words associated with the first and second commands
</figcaption>
</figure>
</div>
</div>
</div>
<p>By checking <span class="invertImage"><a href="#fig-spectrograms" class="quarto-xref">Figure&nbsp;9</a></span>, we can observe how the second command’s wake word, shows a wider range of frequencies, especially at the beginning of the word “<em>Alexa</em>”. Moreover, the lower frequencies in this wake word are louder than any other part of both wake words. Importantly, the second wake word also seems to have higher variability in terms of intensity.</p>
</section>
</section>
<section id="acoustic-feature-extraction" class="level2">
<h2 class="anchored" data-anchor-id="acoustic-feature-extraction">Acoustic feature extraction</h2>
<p>After visually inspecting the audio, we move on to acoustic feature extraction. Visual examination helps us understand vocal features like amplitude and fundamental frequency, but it’s more of a qualitative overview. This overview can guide us in preprocessing or identifying specific areas that need attention. Getting a greater understanding of the audio data requires extracting numerical information that we can obtain through acoustic feature extraction. This process converts auditory signals into measurable characteristics, allowing for a more detailed analysis. Hence, we proceed to extract some key vocal features across the time, amplitude, frequency, and spectral domains.</p>
<section id="time-associated-characteristics" class="level3">
<h3 class="anchored" data-anchor-id="time-associated-characteristics">Time associated characteristics</h3>
<p>The primary measure in the time domain is <strong>duration</strong>, usually expressed in seconds or milliseconds. It indicates the temporal length of a soundwave. The <code>duration()</code> function in the <code>seewave</code> package facilitates the direct extraction of a sound object’s duration in seconds. By applying this function to two commands, we observe that the first command has a shorter duration (6.93 seconds), compared to the second command (7.68 seconds).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">duration</span>(cmd1.filtered)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6.932744</code></pre>
</div>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">duration</span>(cmd2.filtered)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7.677347</code></pre>
</div>
</div>
<p>The <code>soundgen</code> package is a handy package for feature extraction, and more specifically its <code>analyze()</code>. This function enables the extraction of various features spanning time, amplitude, frequency, and spectral domains. Examples include the fundamental frequency, percentage of voiced frames, amplitude, Harmonics-to-Noise ratio, and more.</p>
<p>When you use the <code>analyze()</code> function, it generates two data.frames. The first, a detailed data.frame (<code>$detailed</code>), breaks down each frame of the analyzed audio, with each column representing a vocal feature. The second, a summarized data.frame (<code>$summary</code>), condenses information to one row per file, summarizing vocal features with statistics like mean and standard deviation.</p>
<p>We can proceed to employ the <code>analyze()</code> function to extract multiple vocal features from both the first and second commands, storing its outcome to <code>feat_cmd1</code> and <code>feat_cmd2</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(soundgen)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>feat_cmd1 <span class="ot">&lt;-</span> <span class="fu">analyze</span>(cmd1.filtered, <span class="at">plot =</span> F)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>feat_cmd2 <span class="ot">&lt;-</span> <span class="fu">analyze</span>(cmd2.filtered, <span class="at">plot =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that we possess two objects containing information on distinct vocal characteristics from the two commands, our next step is to complement and quantify some of the key insights derived from our previous visualizations. In <span class="invertImage"><a href="#fig-oscillograms" class="quarto-xref">Figure&nbsp;4</a></span>, we observed differences in voice breaks between both commands. Specifically, the first command exhibited a longer voice break between the wake word and the rest of the command, whereas the second command had an extended voice break between “<em>by Dana</em>” and “<em>on my Spotify</em>”.</p>
<p>Despite these observations, visually determining which command has a lower proportion of voice breaks was challenging. To address this, we can observe the <strong>percentage of voiced frames</strong> extracted by the <code>analyze()</code> function. This can be achieved by extracting the <code>voiced</code> column from the <code>summary</code> data.frame for both <code>feat_cmd1</code> and <code>feat_cmd2</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Returns the proportion of voiced samples</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>voiced</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5217391</code></pre>
</div>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>voiced</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5588235</code></pre>
</div>
</div>
<p>Revealing a greater percentage of voiced frames in the second (55.88%) compared to the first command (52.17%). In other words, the second command has a lower percentage of unvoiced frames (voice breaks) than the first command. This information can be easily translated into total seconds of voice breaks by subtracting the <code>voiced</code> value from 1 and multiplying the result by the duration of each command:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>(<span class="dv">1</span> <span class="sc">-</span> feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>voiced) <span class="sc">*</span> <span class="fu">duration</span>(cmd1.filtered)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.31566</code></pre>
</div>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>(<span class="dv">1</span> <span class="sc">-</span> feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>voiced) <span class="sc">*</span> <span class="fu">duration</span>(cmd2.filtered)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.387065</code></pre>
</div>
</div>
<p>When examining the duration of voice breaks in seconds, we can still see that the first command has longer duration voice breaks. However, this difference is more pronounced in relative terms, considering that the length of the first command is shorter than that of the second.</p>
<p>In addition, as we previously saw in <span class="invertImage"><a href="#fig-oscillograms" class="quarto-xref">Figure&nbsp;4</a></span> is that the first command displays a lengthier voice break between the wake word and the subsequent part of the command compared to the second command. Thus, we may think that excluding that part, the second command has a greater amount of voice breaks, i.e.&nbsp;that the duration of the voice breaks in the rest of the command is lengthier.</p>
<p>Therefore, it’s interesting to examine the percentage of voice breaks solely within the rest of the command, excluding the wake word and the break between it and the remainder of the command. To achieve this, we use the <code>deletew()</code> function to remove the portion of each command containing the wake word. Subsequently, we ensure the elimination of all unvoiced frames preceding the remaining command section using the <code>noSilence()</code> function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>cmd1.without.wakeword <span class="ot">&lt;-</span> <span class="fu">deletew</span>(cmd1.filtered, <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">output =</span> <span class="st">"Wave"</span>)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>cmd1.without.wakeword <span class="ot">&lt;-</span> <span class="fu">noSilence</span>(cmd1.without.wakeword, <span class="at">level =</span> <span class="dv">25</span>)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>feat_cmd1_no_wakeword <span class="ot">&lt;-</span> <span class="fu">analyze</span>(cmd1.without.wakeword, <span class="at">plot =</span> F)</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>cmd2.without.wakeword <span class="ot">&lt;-</span> <span class="fu">deletew</span>(cmd2.filtered, <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">output =</span> <span class="st">"Wave"</span>)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>cmd2.without.wakeword <span class="ot">&lt;-</span> <span class="fu">noSilence</span>(cmd2.without.wakeword, <span class="at">level =</span> <span class="dv">25</span>)</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>feat_cmd2_no_wakeword <span class="ot">&lt;-</span> <span class="fu">analyze</span>(cmd2.without.wakeword, <span class="at">plot =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After doing that, we can now extract the proportion of voiced frames by referencing the <code>voiced</code> column in the <code>summary</code> data.frame of the generated output:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1_no_wakeword<span class="sc">$</span>summary<span class="sc">$</span>voiced</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7043011</code></pre>
</div>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2_no_wakeword<span class="sc">$</span>summary<span class="sc">$</span>voiced</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.6300813</code></pre>
</div>
</div>
<p>These values reveal that after removing the wake word and the voice break between it and the subsequent part of the command, the first command exhibits a higher proportion of voiced frames (70.43%) compared to the second command (63.01%). Consequently, when excluding the wake word, the voice breaks in the second command are longer than those in the first command.</p>
<p>Therefore, the first command has an overall greater proportion of voice breaks than the second command. However, this increased proportion of voice breaks is largely attributed to the extended break following the wake word. Once we eliminate the wake word and the subsequent break from both commands, it becomes evident that the second command actually has a higher proportion of voice breaks.</p>
</section>
<section id="intensity-associated-characteristics" class="level3">
<h3 class="anchored" data-anchor-id="intensity-associated-characteristics">Intensity associated characteristics</h3>
<p>Previously, we delved into this domain by inspecting the oscillograms for the two commands. In doing so, we discerned subtle distinctions in the shapes of the individual words within each command. Expanding on this observation, our subsequent action entails quantifying the central point around which the <strong>amplitude</strong> tends to fluctuate within each command. This quantification is achieved by calculating the mean of the amplitude across each command. Additionally, we aim to measure the extent of deviation from this central point, which we will quantify using the standard deviation of the amplitude.</p>
<p>As previously said, the amplitude of a soundwave indicates its power or loudness, where smaller amplitudes represent softer sounds, and larger amplitudes denote louder ones. It essentially measures how far air particles deviate from their usual position. It’s important to note that these deviations can be both positive and negative. To tackle this, a common method for measuring amplitude is using the root mean square.</p>
<p>The <code>analyze()</code> function extracts the root mean square amplitude (<code>ampl</code>), which calculates the root mean square of the amplitude, excluding unvoiced frames. However, when summarizing this value over a time range, it might be lower than its actual value because unvoiced segments are considered. To address this, the <code>analyze()</code> function also extracts the root mean square amplitude for only the voiced areas (<code>ampl_noSilence</code>). Therefore, we proceed to compare the average root mean square amplitude, excluding unvoiced areas, between the first and the second command:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>ampl_noSilence_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.00150876</code></pre>
</div>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>ampl_noSilence_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.001395994</code></pre>
</div>
</div>
<p>Examining these values, we notice that the first command, on average, has a slightly higher amplitude than the second command. Moving forward, our next step involves determining the extent to which the amplitude deviates from this average within each command. This variability is quantified through the calculation of the standard deviation, which can also be obtained from the <code>summary</code> data.frame generated by the <code>analyze()</code> function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>ampl_noSilence_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0009200839</code></pre>
</div>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>ampl_noSilence_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0009812488</code></pre>
</div>
</div>
<p>We can observe that both commands have nearly identical standard deviations, indicating similar variations in amplitude for both commands.</p>
<p>Similarly, we could obtain information regarding the subjective loudness through the <code>loudness</code> column extracted through the <code>analyze()</code> function, providing a more comprehensive measure:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>loudness_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.483008</code></pre>
</div>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>loudness_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4876107</code></pre>
</div>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>loudness_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1864108</code></pre>
</div>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>loudness_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1804802</code></pre>
</div>
</div>
<p>Similar to the analysis of amplitude, we observe a close resemblance in both the average and standard deviation of loudness between the two commands.</p>
<p>To get into a higher level of granularity, we could also extract such information for the wake words associated with each command. To do so, first, we need to use the <code>analyze()</code> function, which we can do in the following way:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>feat_w1 <span class="ot">&lt;-</span> <span class="fu">analyze</span>(w1, <span class="at">plot =</span> F) </span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>feat_w2 <span class="ot">&lt;-</span> <span class="fu">analyze</span>(w2, <span class="at">plot =</span> F) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we can move forward to compute the average value and standard deviation of the loudness for the wake words associated with each command by accessing to the columns <code>loudness_mean</code> and <code>loudness_sd</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>feat_w1<span class="sc">$</span>summary<span class="sc">$</span>loudness_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2332632</code></pre>
</div>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>feat_w2<span class="sc">$</span>summary<span class="sc">$</span>loudness_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.314038</code></pre>
</div>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>feat_w1<span class="sc">$</span>summary<span class="sc">$</span>loudness_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0969784</code></pre>
</div>
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>feat_w2<span class="sc">$</span>summary<span class="sc">$</span>loudness_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1460193</code></pre>
</div>
</div>
<p>As we can observe, there are differences in loudness between the two wake words. The wake word in the second command exhibits both a higher average loudness (0.31 sone) and a greater standard deviation in loudness (0.15 sone) compared to the first (M = 0.31 sone, SD = 0.15 sone).</p>
</section>
<section id="frequency-associated-characteristics" class="level3">
<h3 class="anchored" data-anchor-id="frequency-associated-characteristics">Frequency associated characteristics</h3>
<p>The <strong>fundamental frequency</strong> (F0) is a key vocal feature in the frequency domain. Similar to the approach taken with amplitude, we will now extract the average and standard deviation of the fundamental frequency using the features previously obtained through the <code>analyze()</code> function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>pitch_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 229.3688</code></pre>
</div>
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>pitch_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 234.4607</code></pre>
</div>
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>pitch_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 40.54858</code></pre>
</div>
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>pitch_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 28.99324</code></pre>
</div>
</div>
<p>Observing how the second command has a slightly higher average fundamental frequency (M = 234.46 Hz) than the first command (M = 229.37 Hz), while also having a higher standard deviation of the fundamental frequency (SD command 1 = 40.55 Hz; SD command 2 = 28.99 Hz).</p>
<p>To get into a higher level of granularity, we can apply the same analysis only to the wake word “<em>Alexa</em>”, by extracting the average and standard deviation of the fundamental frequency for the two wake words by accessing the previously created <code>feat_w1</code> and <code>feat_w2</code> objects:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>feat_w1<span class="sc">$</span>summary<span class="sc">$</span>pitch_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 171.4803</code></pre>
</div>
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>feat_w2<span class="sc">$</span>summary<span class="sc">$</span>pitch_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 238.2434</code></pre>
</div>
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>feat_w1<span class="sc">$</span>summary<span class="sc">$</span>pitch_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 13.13345</code></pre>
</div>
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>feat_w2<span class="sc">$</span>summary<span class="sc">$</span>pitch_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 53.01586</code></pre>
</div>
</div>
<p>In this case, the previously observed differences become even more pronounced—the second wake word has a much higher average fundamental frequency (M = 238.24 Hz) and standard deviation (SD = 53.02 Hz) than the first (M = 171.48 Hz; SD = 13.13 Hz).</p>
<p>In addition to extracting details about the fundamental frequency, we can delve into information about the formants. In <span class="invertImage"><a href="#fig-formanttrack" class="quarto-xref">Figure&nbsp;8</a></span>, we already saw that the track of the formants presented slight differences between the two wakewords. Consequently, our next step involves further characterising these differences, by extracting both the average and standard deviation of the frequency for the <strong>first formant</strong> (F1) across various commands and wake words. This information is accessible through the <code>f1_freq_mean</code> and <code>f1_freq_sd</code> columns in the <code>detailed</code> data.frame:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>f1_freq_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 346.1914</code></pre>
</div>
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>f1_freq_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 392.5255</code></pre>
</div>
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>f1_freq_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 117.9901</code></pre>
</div>
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>f1_freq_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 242.5611</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>feat_w1<span class="sc">$</span>summary<span class="sc">$</span>f1_freq_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 377.39</code></pre>
</div>
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>feat_w2<span class="sc">$</span>summary<span class="sc">$</span>f1_freq_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 427.1445</code></pre>
</div>
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>feat_w1<span class="sc">$</span>summary<span class="sc">$</span>f1_freq_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 65.50526</code></pre>
</div>
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>feat_w2<span class="sc">$</span>summary<span class="sc">$</span>f1_freq_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 92.08512</code></pre>
</div>
</div>
<p>As we can observe, the second command exhibits a slightly higher average frequency for the first formant (M = 392.53Hz) compared to the first command (M = 346.19 Hz). However, it’s noteworthy that the standard deviation of the first formant is greater for the second command (SD = 242.56 Hz) than for the first command (SD = 117.99 Hz).</p>
<p>Upon closer examination of the wake words, this relationship undergoes partial modification. The wake word associated with the second command displays both a higher average and standard deviation for the frequency of the first formant (M = 427.14 Hz; SD = 92.09 Hz) in comparison to the wake word linked to the first command (M = 377.39 Hz; SD = 92.09 Hz).</p>
<p>Similarly, we can extract that information for the <strong>second formant</strong> (F2), by accessing the <code>f2_freq_mean</code> and <code>f2_freq_sd columns</code> in the <code>detailed</code> data data.frame:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>f2_freq_mean </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 785.8252</code></pre>
</div>
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>f2_freq_mean </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 879.1609</code></pre>
</div>
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>f2_freq_sd </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 433.0889</code></pre>
</div>
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>f2_freq_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 492.0018</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>feat_w1<span class="sc">$</span>summary<span class="sc">$</span>f2_freq_mean </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 728.2679</code></pre>
</div>
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>feat_w2<span class="sc">$</span>summary<span class="sc">$</span>f2_freq_mean </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 849.607</code></pre>
</div>
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>feat_w1<span class="sc">$</span>summary<span class="sc">$</span>f2_freq_sd </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 253.4525</code></pre>
</div>
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>feat_w2<span class="sc">$</span>summary<span class="sc">$</span>f2_freq_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 130.4056</code></pre>
</div>
</div>
<p>Examining these values, we observe that the first command has a higher average and standard deviation for the frequency of the second formant (M = 785.83 Hz; SD = 433.09 Hz) compared to the second command (M = 879.16 Hz, SD = 492 Hz).</p>
<p>Zooming in on the wake words, we note that the average frequency for the wake word associated with the second command (M = 849.61 Hz) is higher than that for the wake word associated with the first command (M = 728.27 Hz). However, it’s interesting to point out that the wake word linked to the first command exhibits a higher standard deviation of the frequency of the second formant (SD = 130.41 Hz) compared to the wake word associated with the second command (SD = 130.41 Hz).</p>
</section>
<section id="spectral-associated-characteristics" class="level3">
<h3 class="anchored" data-anchor-id="spectral-associated-characteristics">Spectral associated characteristics</h3>
<p>Spectral features of a soundwave capture disturbances within the sound. Features assessing the spectral qualities of a soundwave typically gauge the level of disturbance or periodicity in the sound. Two such features of disturbances are the <strong>Harmonics-to-Noise Ratio (HNR)</strong> and the <strong>Wiener entropy (entropy)</strong>, both directly extractable through the <code>analyze()</code> function.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Harmonics-to-Noise Ratio and Weiner Entropy">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Harmonics-to-Noise Ratio and Weiner Entropy
</div>
</div>
<div class="callout-body-container callout-body">
<p>The Harmonics-to-Noise Ratio (HNR) measures the additive noise level in a voice signal. Lower HNR values signify a higher proportion of noise in comparison to the harmonic components, often associated with breathy or hoarse sounds. Consequently, the higher the HNR, the clearer the voice sounds.</p>
<p>The Wiener entropy, commonly referred to as spectral flatness, serves to measure the degree to which a sound exhibits characteristics of a pure tone rather than resembling noise. This quantification is achieved by analyzing the shape of the spectrum, which represents the distribution of energy across different frequencies in the signal.<br>
When the spectrum is flat, indicating a balanced energy distribution, the Wiener entropy value approaches 1.0, signifying white noise. Conversely, if the spectrum is spiky, with energy concentrated at specific frequencies, the Wiener entropy value tends towards 0, indicating a pure tone.</p>
</div>
</div>
<p>Therefore, we proceed to extract the average entropy and HNR for the two commands:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>entropy_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.03265698</code></pre>
</div>
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>entropy_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.03072856</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>HNR_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 15.92719</code></pre>
</div>
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>HNR_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 16.74486</code></pre>
</div>
</div>
<p>Upon examining the average entropy for the two commands, it becomes evident that their values are quite comparable. It’s noteworthy, however, that these values are relatively close to 0, indicating a resemblance more akin to a pure tone than to white noise.</p>
<p>In terms of the average HNR, both commands also possess similar values, having the second command with a slightly higher value (M = 16.74 dB) than the first (M = 15.93 dB). The high HNR value for both commands indicates a substantial dominance of harmonics to noise within the audio signals.</p>
<p>In addition to comparing the means of the entropy and HNR, we will also observe their standard deviation as in the previous cases:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>entropy_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.03373136</code></pre>
</div>
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>entropy_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.02609803</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>feat_cmd1<span class="sc">$</span>summary<span class="sc">$</span>HNR_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6.61309</code></pre>
</div>
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>feat_cmd2<span class="sc">$</span>summary<span class="sc">$</span>HNR_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6.178095</code></pre>
</div>
</div>
<p>Seeing how for both commands, the standard deviation of the entropy and the HNR is fairly similar between the two commands.</p>
<p>As in the previous cases, we could also zoom in on the isolated wake word for each command and extract these statistics regarding the HNR and the entropy:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>feat_w1<span class="sc">$</span>summary<span class="sc">$</span>entropy_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.02015783</code></pre>
</div>
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a>feat_w1<span class="sc">$</span>summary<span class="sc">$</span>entropy_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.01381312</code></pre>
</div>
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>feat_w1<span class="sc">$</span>summary<span class="sc">$</span>HNR_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 13.37802</code></pre>
</div>
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>feat_w1<span class="sc">$</span>summary<span class="sc">$</span>HNR_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4.217952</code></pre>
</div>
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>feat_w2<span class="sc">$</span>summary<span class="sc">$</span>entropy_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0267721</code></pre>
</div>
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>feat_w2<span class="sc">$</span>summary<span class="sc">$</span>entropy_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.02322313</code></pre>
</div>
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>feat_w2<span class="sc">$</span>summary<span class="sc">$</span>HNR_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 11.21771</code></pre>
</div>
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>feat_w2<span class="sc">$</span>summary<span class="sc">$</span>HNR_sd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.512729</code></pre>
</div>
</div>
<p>As in the case of the commands, we can see how the different values between the two wake words are quite similar. However, the values for the HNR are lower than for the command, implying that there’s a lower proportion of harmonics in relation to noise. Thus, the speaker when saying the command has slightly hoarser voice compared to the rest of the command. This hoarseness could be linked to a direct increase in vocal intensity when initiating speech.</p>
</section>
<section id="vocal-features-summary" class="level3">
<h3 class="anchored" data-anchor-id="vocal-features-summary">Vocal features summary</h3>
<p>After extracting the various vocal features from the two commands, we present a well-organized table, <a href="#tbl-vocal-features" class="quarto-xref">Table&nbsp;1</a>, which encapsulates these characteristics for each command. Furthermore, we also include the vocal characteristics for the isolated wake words associated with both commands.</p>
<div class="table-wrapper">
<div id="tbl-vocal-features" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-vocal-features-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Vocal features for the two commands and isolated wake words
</figcaption>
<div aria-describedby="tbl-vocal-features-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;">Command 1</th>
<th style="text-align: center;">Command 2</th>
<th style="text-align: center;">Wake word 1</th>
<th style="text-align: center;">Wake word 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Time domain</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>Duration</td>
<td style="text-align: center;">6.93s</td>
<td style="text-align: center;">7.68 s</td>
<td style="text-align: center;">0.63 s</td>
<td style="text-align: center;">0.63 s</td>
</tr>
<tr class="odd">
<td>Percentage of voiced frames</td>
<td style="text-align: center;">52.17 %</td>
<td style="text-align: center;">55.88 %</td>
<td style="text-align: center;">58.33 %</td>
<td style="text-align: center;">62.5 %</td>
</tr>
<tr class="even">
<td>Percentage of voiced frames, excluding wake word and subsequent break</td>
<td style="text-align: center;">70.43 %</td>
<td style="text-align: center;">63.01 %</td>
<td style="text-align: center;">—</td>
<td style="text-align: center;">—</td>
</tr>
<tr class="odd">
<td><strong>Amplitude domain</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>Average root mean square of the amplitude</td>
<td style="text-align: center;">0.0015</td>
<td style="text-align: center;">0.0014</td>
<td style="text-align: center;">7^{-4}</td>
<td style="text-align: center;">7^{-4}</td>
</tr>
<tr class="odd">
<td>Standard deviation of the root mean square of the amplitude</td>
<td style="text-align: center;">9^{-4}</td>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">3^{-4}</td>
<td style="text-align: center;">5^{-4}</td>
</tr>
<tr class="even">
<td>Average loudness</td>
<td style="text-align: center;">0.48 sone</td>
<td style="text-align: center;">0.49 sone</td>
<td style="text-align: center;">0.23 sone</td>
<td style="text-align: center;">0.31 sone</td>
</tr>
<tr class="odd">
<td>Standard deviation of the loudness</td>
<td style="text-align: center;">0.19 sone</td>
<td style="text-align: center;">0.18 sone</td>
<td style="text-align: center;">0.1 sone</td>
<td style="text-align: center;">0.15 sone</td>
</tr>
<tr class="even">
<td><strong>Frequency domain</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td>Average fundamental frequency</td>
<td style="text-align: center;">229.37 Hz</td>
<td style="text-align: center;">234.46 Hz</td>
<td style="text-align: center;">171.48 Hz</td>
<td style="text-align: center;">238.24 Hz</td>
</tr>
<tr class="even">
<td>Standard deviation of the fundamental frequency</td>
<td style="text-align: center;">40.55 Hz</td>
<td style="text-align: center;">28.99 Hz</td>
<td style="text-align: center;">13.13 Hz</td>
<td style="text-align: center;">53.02 Hz</td>
</tr>
<tr class="odd">
<td>Average first formant (F1) frequency</td>
<td style="text-align: center;">346.19 Hz</td>
<td style="text-align: center;">392.53 Hz</td>
<td style="text-align: center;">377.39 Hz</td>
<td style="text-align: center;">427.14 Hz</td>
</tr>
<tr class="even">
<td>Standard deviation of the first formant (F1) frequency</td>
<td style="text-align: center;">117.99 Hz</td>
<td style="text-align: center;">242.56 Hz</td>
<td style="text-align: center;">65.51 Hz</td>
<td style="text-align: center;">92.09 Hz</td>
</tr>
<tr class="odd">
<td>Average second formant (F2) frequency</td>
<td style="text-align: center;">785.83 Hz</td>
<td style="text-align: center;">879.16 Hz</td>
<td style="text-align: center;">728.27 Hz</td>
<td style="text-align: center;">849.61 Hz</td>
</tr>
<tr class="even">
<td>Standard deviation of the second formant (F2) frequency</td>
<td style="text-align: center;">433.09 Hz</td>
<td style="text-align: center;">492 Hz</td>
<td style="text-align: center;">253.45 Hz</td>
<td style="text-align: center;">130.41 Hz</td>
</tr>
<tr class="odd">
<td><strong>Spectral domain</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>Average Wiener entropy</td>
<td style="text-align: center;">0.03</td>
<td style="text-align: center;">0.03</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.03</td>
</tr>
<tr class="odd">
<td>Standard deviation of the Wiener entropy</td>
<td style="text-align: center;">0.03</td>
<td style="text-align: center;">0.03</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.02</td>
</tr>
<tr class="even">
<td>Average Harmonics-to-Noise Ratio</td>
<td style="text-align: center;">15.93 dB</td>
<td style="text-align: center;">16.74 dB</td>
<td style="text-align: center;">13.38 dB</td>
<td style="text-align: center;">11.22 dB</td>
</tr>
<tr class="odd">
<td>Standard deviation of the Harmonics-to-Noise Ratio</td>
<td style="text-align: center;">6.61 dB</td>
<td style="text-align: center;">6.18 dB</td>
<td style="text-align: center;">4.22 dB</td>
<td style="text-align: center;">3.51 dB</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
<section id="wakeword" class="level4">
<h4 class="anchored" data-anchor-id="wakeword">Wakeword</h4>
<p>Looking at <a href="#tbl-vocal-features" class="quarto-xref">Table&nbsp;1</a> we can easily notice that the second command’s wake word is spoken more loudly, especially in the initial part of the word, as we previously observed in <span class="invertImage"><a href="#fig-spectrograms" class="quarto-xref">Figure&nbsp;9</a></span>. This illustrates how, in the second command’s wake word, the speaker raises their voice to say “<em>Ale</em>.” Additionally, the second command has a higher percentage of voiced frames, mainly because the speaker prolongs the letter “<em>e</em>”, as seen in <span class="invertImage"><a href="#fig-spectrograms" class="quarto-xref">Figure&nbsp;9</a></span>. Furthermore, we observe that the second command’s wake word has a higher average and standard deviation of the fundamental frequency. Specifically, this frequency rises during the first part of the command, corresponding to “<em>Ale</em>”, and then decreases again, as shown in <span class="invertImage"><a href="#fig-pitch" class="quarto-xref">Figure&nbsp;7</a></span>. This indicates that in the initial part of the word “<em>Alexa</em>”, the voice is higher, suggesting the speaker is raising their voice. Moreover, in the second command’s wake word, the average frequencies for the first two formants are also higher, indicating a more forceful delivery.</p>
</section>
<section id="full-command" class="level4">
<h4 class="anchored" data-anchor-id="full-command">Full command</h4>
<p>The second command is lengthier than the first, this is primarily because when excluding the wake word and the voice break between the wake word and the rest of the command, there’s a higher percentage of unvoiced frames, i.e.&nbsp;lengthier voice breaks. By listening to the audio and also looking at <span class="invertImage"><a href="#fig-oscillograms" class="quarto-xref">Figure&nbsp;4</a></span>, we can observe how the speaker is emphasizing the individual words, hoping that in this way the device will understand the command, unlike in the first command. As, in the case of the wake words, we can also observe an average higher fundamental frequency for the second command’s wake word, indicating a higher voice. In addition, the frequencies for the first and second formant are also higher, indicating a more forceful delivery.</p>
<p>Thus, we could hear how the speaker was expressing higher frustration on the second command and by decomposing the command into several audio characteristics that we have visualized and quantified, we have gained a deeper understanding of what’s driving our perception of the user’s frustration while interacting with Alexa.</p>
</section>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>In this analysis, we delved into a user’s interaction with Alexa. The user initially instructed Alexa to play “<em>Something’s Cooking in My Kitchen</em>” by Dana. Unfortunately, Alexa struggled to comprehend the command due to the user’s Scottish accent. Frustrated by this, the user repeated the command in a tone reflecting her annoyance.</p>
<p>To understand the impact of these different deliveries on the commands, we compared the two instances. The first command was delivered in a natural and composed manner, while the second was tinged with frustration. Our approach involved going through the whole voice analytics pipeline breaking down the speech into various characteristics and scrutinizing these aspects for disparities between the commands.</p>
<p>By dissecting the speech and quantifying different characteristics, we were able to gain a nuanced understanding of what changed between the two commands. This not only enhanced our perception of user frustration but also provided valuable insights into the nuanced elements contributing to the interaction.</p>
<p>It’s important to note that this analysis serves as a basic tutorial. We directly compared two commands from the same user with almost identical content (except for the addition of the word “<em>my</em>” on the second command). In more advanced voice analytics, we would analyze more than just two audios from a single speaker, employing more sophisticated statistical methods or even training machine learning models to predict outcomes of interest. Hence, this post serves as an introduction, offering fundamental concepts of voice analytics from a practical perspective.</p>


</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<div class="giscus">
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</div></body></html>